{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled54.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOSlWqGVNQKxE+2ikwvYjYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sheraz55/Deep-learning-course-practice/blob/main/Chapter%208%20(Neaural%20transfer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLxTm-ATV1Hw"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRaJdfQnWVag"
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86LGSxyxYL2B"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import schedules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FovzU-_kWyS8"
      },
      "source": [
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkkwaAZKXnN8"
      },
      "source": [
        "discriminator_optimizer = keras.optimizers.RMSprop( learning_rate=0.0008,  clipvalue=1.0,  decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer,loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeIhX3jOWZBV"
      },
      "source": [
        "discriminator.trainable = False\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "gan_optimizer = keras.optimizers.RMSprop(learning_rate=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_kUXoU3WgJv"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = x_train[y_train.flatten() == 6]\n",
        "x_train = x_train.reshape(\n",
        "(x_train.shape[0],) +\n",
        "(height, width, channels)).astype('float32') / 255.\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = '/content/New'\n",
        "start = 0\n",
        "\n",
        "for step in range(iterations):\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,  latent_dim))\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "  stop = start + batch_size\n",
        "\n",
        "  real_images = x_train[start: stop]\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,  latent_dim))\n",
        "  \n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "  start += batch_size\n",
        "\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('adversarial loss:', a_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt8N90IZZChU"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVGsS1mUyrAh"
      },
      "source": [
        "img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "img.save(os.path.join(save_dir,'generated_frog' + str(step) + '.png'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLe8BpnIy7L7"
      },
      "source": [
        "img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "img.save(os.path.join(save_dir,'real_frog' + str(step) + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}